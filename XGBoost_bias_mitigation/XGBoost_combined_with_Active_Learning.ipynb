{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from scipy.stats import entropy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/cmottez/CS231N_Lightweight_Bias_Mitigation_Chest_Xray')\n",
    "\n",
    "from metrics import compute_metrics, compute_kl_divergence_sex, compute_kl_divergence_age, compute_kl_divergence_race, compute_metrics_subcath, bias_table, bias_table_auprc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV with your extracted embeddings and the demographics info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../CNN_from_scratch/final_embeddings_train.pkl')\n",
    "valid = pd.read_pickle('../CNN_from_scratch/final_embeddings_val.pkl')\n",
    "test = pd.read_pickle('../CNN_from_scratch/final_embeddings_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_1014</th>\n",
       "      <th>embedding_1015</th>\n",
       "      <th>embedding_1016</th>\n",
       "      <th>embedding_1017</th>\n",
       "      <th>embedding_1018</th>\n",
       "      <th>embedding_1019</th>\n",
       "      <th>embedding_1020</th>\n",
       "      <th>embedding_1021</th>\n",
       "      <th>embedding_1022</th>\n",
       "      <th>embedding_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train/patient02424/study8/view1_frontal.jpg</td>\n",
       "      <td>0.577020</td>\n",
       "      <td>0.225139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.103660</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.210349</td>\n",
       "      <td>0.213531</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.067287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train/patient08517/study10/view1_frontal.jpg</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>0.408154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058802</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004865</td>\n",
       "      <td>0.690274</td>\n",
       "      <td>0.037327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140191</td>\n",
       "      <td>0.386501</td>\n",
       "      <td>0.005471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train/patient03164/study14/view1_frontal.jpg</td>\n",
       "      <td>0.036016</td>\n",
       "      <td>0.260678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.123461</td>\n",
       "      <td>0.089736</td>\n",
       "      <td>0.258684</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.161937</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train/patient28576/study3/view1_frontal.jpg</td>\n",
       "      <td>0.498498</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344112</td>\n",
       "      <td>0.363110</td>\n",
       "      <td>0.349447</td>\n",
       "      <td>0.067082</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>0.091146</td>\n",
       "      <td>0.307771</td>\n",
       "      <td>0.309890</td>\n",
       "      <td>0.467222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train/patient35066/study5/view1_frontal.jpg</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.254078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048831</td>\n",
       "      <td>0.106363</td>\n",
       "      <td>0.082369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153965</td>\n",
       "      <td>0.548223</td>\n",
       "      <td>0.739487</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>0.070378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  race  age  Cardiomegaly  Edema  Lung Opacity  Pleural Effusion  \\\n",
       "0    0     0    0             0      0             0                 1   \n",
       "1    0     1    0             1      1             1                 0   \n",
       "2    0     0    1             0      0             1                 1   \n",
       "3    1     0    0             0      0             0                 0   \n",
       "4    1     0    0             0      0             0                 1   \n",
       "\n",
       "                                  path_to_image  embedding_0  embedding_1  \\\n",
       "0   train/patient02424/study8/view1_frontal.jpg     0.577020     0.225139   \n",
       "1  train/patient08517/study10/view1_frontal.jpg     0.131081     0.408154   \n",
       "2  train/patient03164/study14/view1_frontal.jpg     0.036016     0.260678   \n",
       "3   train/patient28576/study3/view1_frontal.jpg     0.498498     0.238422   \n",
       "4   train/patient35066/study5/view1_frontal.jpg     0.203171     0.254078   \n",
       "\n",
       "   ...  embedding_1014  embedding_1015  embedding_1016  embedding_1017  \\\n",
       "0  ...        0.026545        0.039251        0.103660        0.115058   \n",
       "1  ...        0.058802        0.018378        0.000000        1.004865   \n",
       "2  ...        0.000021        0.000000        0.000000        0.007108   \n",
       "3  ...        0.344112        0.363110        0.349447        0.067082   \n",
       "4  ...        0.048831        0.106363        0.082369        0.000000   \n",
       "\n",
       "   embedding_1018  embedding_1019  embedding_1020  embedding_1021  \\\n",
       "0        0.078481        0.210349        0.213531        0.023333   \n",
       "1        0.690274        0.037327        0.000000        0.140191   \n",
       "2        0.123461        0.089736        0.258684        0.001910   \n",
       "3        0.008733        0.033510        0.091146        0.307771   \n",
       "4        0.153965        0.548223        0.739487        0.015420   \n",
       "\n",
       "   embedding_1022  embedding_1023  \n",
       "0        0.020806        0.067287  \n",
       "1        0.386501        0.005471  \n",
       "2        0.161937        0.000000  \n",
       "3        0.309890        0.467222  \n",
       "4        0.073128        0.070378  \n",
       "\n",
       "[5 rows x 1032 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = train[[f\"embedding_{i}\" for i in range(1024)]]\n",
    "valid_embeddings = valid[[f\"embedding_{i}\" for i in range(1024)]]\n",
    "test_embeddings = test[[f\"embedding_{i}\" for i in range(1024)]]\n",
    "\n",
    "# Diseases to predict\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']\n",
    "\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "\n",
    "X_train = train_embeddings\n",
    "X_test = test_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sex = test['sex']\n",
    "y_race = test['race']\n",
    "y_age = test['age']\n",
    "\n",
    "\n",
    "y_train_sex = train['sex']\n",
    "y_train_race = train['race']\n",
    "y_train_age = train['age']\n",
    "group_info = train[['sex','race','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_751471/3958011541.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train.replace(-1, 0, inplace=True)\n",
      "/tmp/ipykernel_751471/3958011541.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test.replace(-1, 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA to reduce embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 30\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "#95% variance means that the selected principal components (reduced dimensions) retain 95% of the total variability present in the original high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA if wanted\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67263, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pool = x_train_subset\n",
    "y_pool = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    \n",
    "    if y_train.shape[1] > 1:\n",
    "        multi_output_model = MultiOutputClassifier(model)\n",
    "        multi_output_model.fit(x_train, y_train)\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test))}) # Dataframe with probabilites \n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "    else:\n",
    "        print(\"Single disease\")\n",
    "        model.fit(x_train, y_train)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            # Dataframe with probabilities for the positive class\n",
    "            y_test_preds_proba = pd.DataFrame(model.predict_proba(x_test)[:, 1], columns=['Probability'])\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uncertainty(probas):\n",
    "    # example: margin sampling for binary: |p-0.5|\n",
    "    # for multi-class use: smallest difference between top two probs\n",
    "    if probas.shape[1] == 2:\n",
    "        return 1.0 - np.abs(probas[:,1] - 0.5) * 2\n",
    "    else:\n",
    "        top2 = np.partition(probas, -2, axis=1)[:, -2:]\n",
    "        return 1.0 - (top2[:,-1] - top2[:,-2])\n",
    "\n",
    "def active_learn(\n",
    "    x_pool,                # unlabeled features pool (DataFrame or array)\n",
    "    y_pool,                # true labels for simulation (array or DataFrame)\n",
    "    group_pool,            # DataFrame with group info (sex/race/age), used for underrepresentation\n",
    "    x_seed, y_seed,        # initial small labeled set\n",
    "    model, \n",
    "    batch_size=50, \n",
    "    n_rounds=10,\n",
    "    diversity_clusters=10\n",
    "):\n",
    "    x_labeled, y_labeled, grp_labeled = x_seed.copy(), y_seed.copy(), group_pool.loc[y_seed.index]\n",
    "    x_unlabeled, y_unlabeled, grp_unlabeled = x_pool.copy(), y_pool.copy(), group_pool.copy()\n",
    "    \n",
    "    for round in range(n_rounds):\n",
    "        # 1) Fit\n",
    "        if isinstance(y_labeled, pd.DataFrame) and y_labeled.shape[1] > 1:\n",
    "            clf = MultiOutputClassifier(model)\n",
    "            clf.fit(x_labeled, y_labeled)\n",
    "        else:\n",
    "            clf = model\n",
    "            clf.fit(x_labeled, y_labeled.values.ravel())\n",
    "        \n",
    "        # 2) Uncertainty on pool\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "\n",
    "            if isinstance(clf, MultiOutputClassifier):\n",
    "                probs = np.stack([est.predict_proba(x_unlabeled) \n",
    "                                  for est in clf.estimators_], axis=2)\n",
    "                \n",
    "                uncs = np.mean([compute_uncertainty(probs[:,:,t]) \n",
    "                                for t in range(probs.shape[2])], axis=0)\n",
    "            else:\n",
    "                probs = clf.predict_proba(x_unlabeled)\n",
    "                uncs = compute_uncertainty(probs)\n",
    "        else:\n",
    "            raise ValueError(\"Model has no predict_proba – implement a margin or entropy on decision_function\")\n",
    "        \n",
    "            # 3) Under‐representation weighting\n",
    "        # Build a single “group key” (sex_race_age) for labeled & unlabeled\n",
    "        def make_key(df):\n",
    "            return df.astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "        labeled_keys   = make_key(grp_labeled)\n",
    "        unlabeled_keys = make_key(grp_unlabeled)\n",
    "\n",
    "        # Compute frequency of each group in the labeled set\n",
    "        freq = labeled_keys.value_counts(normalize=True)\n",
    "\n",
    "        # Map each unlabeled sample to weight = 1/freq(group)\n",
    "        # If a new combination somehow appears, fall back to the smallest freq\n",
    "        min_freq = freq.min()\n",
    "        weights = unlabeled_keys.map(lambda k: 1.0 / freq.get(k, min_freq))\n",
    "\n",
    "        # Now your sample_scores line works as expected:\n",
    "        sample_scores = uncs * weights.values\n",
    "\n",
    "        # 4) Diversity clustering: pick top B*cluster_factor and cluster into B clusters\n",
    "        topk = np.argsort(sample_scores)[-batch_size * diversity_clusters:]\n",
    "        kmeans = KMeans(n_clusters=batch_size, random_state=round).fit(x_unlabeled.iloc[topk])\n",
    "        # pick one from each cluster: the most uncertain in that cluster\n",
    "        new_idx = []\n",
    "        for c in range(batch_size):\n",
    "            members = np.where(kmeans.labels_ == c)[0]\n",
    "            cluster_idxs = topk[members]\n",
    "            # pick highest score\n",
    "            pick = cluster_idxs[np.argmax(sample_scores[cluster_idxs])]\n",
    "            new_idx.append(pick)\n",
    "        \n",
    "        # 5) Add to labeled, remove from pool\n",
    "        x_new = x_unlabeled.iloc[new_idx]\n",
    "        y_new = y_unlabeled.iloc[new_idx]\n",
    "        grp_new = grp_unlabeled.iloc[new_idx]\n",
    "        \n",
    "        x_labeled = pd.concat([x_labeled, x_new], axis=0)\n",
    "        y_labeled = pd.concat([y_labeled, y_new], axis=0)\n",
    "        grp_labeled = pd.concat([grp_labeled, grp_new], axis=0)\n",
    "        \n",
    "        x_unlabeled = x_unlabeled.drop(x_new.index)\n",
    "        y_unlabeled = y_unlabeled.drop(y_new.index)\n",
    "        grp_unlabeled = grp_unlabeled.drop(grp_new.index)\n",
    "        \n",
    "        print(f\"Round {round+1}/{n_rounds}: added {len(new_idx)} samples, labeled set size = {len(x_labeled)}\")\n",
    "    \n",
    "    return clf, x_labeled, y_labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pool = pd.DataFrame(x_pool)\n",
    "y_pool = pd.DataFrame(y_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = 15000\n",
    "x_seed, y_seed = x_pool[:to_keep], y_pool[:to_keep]\n",
    "\n",
    "# unlabeled pool is the rest\n",
    "x_pool2 = x_pool[to_keep:]\n",
    "y_pool2 = y_pool[to_keep:]\n",
    "group_pool2 = group_info.iloc[to_keep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pool2.reset_index(drop=True, inplace=True)\n",
    "y_pool2.reset_index(drop=True, inplace=True)\n",
    "group_pool2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_test, model):\n",
    "    \"\"\"\n",
    "    Fits (or refits) your model on (x_train, y_train) and returns a DataFrame of \n",
    "    per-disease probability-for-class-1 on x_test.\n",
    "    \"\"\"\n",
    "\n",
    "    is_multi = (hasattr(y_train, \"shape\") and y_train.shape[-1] > 1)\n",
    "\n",
    "    if is_multi:\n",
    "        if isinstance(model, MultiOutputClassifier):\n",
    "            m = model\n",
    "        else:\n",
    "            m = MultiOutputClassifier(model)\n",
    "        m.fit(x_train, y_train)\n",
    "        \n",
    "        proba_lists = m.predict_proba(x_test)\n",
    "        y_test_preds_proba = pd.DataFrame({\n",
    "            disease: probs[:, 1]\n",
    "            for disease, probs in zip(diseases, proba_lists)\n",
    "        })\n",
    "    else:\n",
    "        if not hasattr(model, \"predict_proba\"):\n",
    "            raise ValueError(\"Model must support predict_proba for single‐output mode\")\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        y_test_preds_proba = pd.DataFrame(\n",
    "            model.predict_proba(x_test)[:, 1],\n",
    "            columns=[\"Probability\"]\n",
    "        )\n",
    "\n",
    "    return m, y_test_preds_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=150,\n",
    "    max_depth=10,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_lambda=5,\n",
    "    reg_alpha=5,\n",
    "    scale_pos_weight=5,\n",
    "    random_state=i\n",
    "    )\n",
    "\n",
    "    learner, X_lab, Y_lab = active_learn(\n",
    "        x_pool2, y_pool2, group_pool2,\n",
    "        x_seed, y_seed,\n",
    "        model=xgb,\n",
    "        batch_size=2000,\n",
    "        n_rounds=10,\n",
    "        diversity_clusters=10\n",
    "    )\n",
    "\n",
    "    X_lab.reset_index(drop=True, inplace=True)\n",
    "    Y_lab.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # final evaluation on held-out x_test_subset, y_test as before\n",
    "    learner, y_pred = train_model(\n",
    "        x_train = X_lab,\n",
    "        y_train = Y_lab,\n",
    "        x_test  = x_test_subset,\n",
    "        model   = learner \n",
    "    )\n",
    "\n",
    "    predictions = y_pred.values\n",
    "    targets = y_test.values\n",
    "\n",
    "    y_pred_df = pd.DataFrame(y_pred)\n",
    "    y_pred_df.columns = diseases\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "    y_test_df.columns = diseases\n",
    "\n",
    "    metrics = compute_metrics(y_pred_df, y_test_df, diseases)\n",
    "    metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old = compute_metrics_subcath(predictions, targets, diseases, y_sex, y_race, y_age)\n",
    "    styled_df, df = bias_table_auprc(metrics, metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old)\n",
    "\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(dataframes, keys=range(len(dataframes)))\n",
    "\n",
    "combined_df = combined_df[['AUPRC', 'AUC', 'Delta AUPRC sex', 'Delta AUPRC race', 'Delta AUPRC age']]\n",
    "\n",
    "df_mean = combined_df.groupby(level=1).mean()\n",
    "df_std = combined_df.groupby(level=1).std() \n",
    "\n",
    "df_mean.reset_index(drop=True, inplace=True)\n",
    "df_std.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_mean.insert(0, 'disease', diseases)\n",
    "df_std.insert(0, 'disease', diseases)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
