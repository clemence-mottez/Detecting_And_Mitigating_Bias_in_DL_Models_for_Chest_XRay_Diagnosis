{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from scipy.stats import entropy\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/cmottez/CS231N_Lightweight_Bias_Mitigation_Chest_Xray')\n",
    "\n",
    "from metrics import compute_metrics, compute_kl_divergence_sex, compute_kl_divergence_age, compute_kl_divergence_race, compute_metrics_subcath, bias_table, bias_table_auprc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV with demographics info + diseases info + image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_train_with_embeddings_extracted.pkl')\n",
    "valid = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_valid_with_embeddings_extracted.pkl')\n",
    "test = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_test_with_embeddings_extracted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>insurance</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0029132624622434378, 0.1020001769065857, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0014348188415169716, 0.0543656125664711, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001982336398214102, 0.040021587163209915, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001741771469824016, 0.0560498870909214, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.678312198957428e-05, 0.12247737497091293, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  race  age  insurance  Atelectasis  Cardiomegaly  Consolidation  \\\n",
       "0       1     0    1          1            1             1              0   \n",
       "1       0     1    0          2            0             0              0   \n",
       "2       0     0    1          1            0             0              0   \n",
       "3       1     1    1          1            0             0              0   \n",
       "4       0     0    0          0            0             0              1   \n",
       "\n",
       "   Edema  Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0      1                           0         1            0             0   \n",
       "1      0                           0         0            0             0   \n",
       "2      0                           0         0            0             1   \n",
       "3      0                           0         0            0             0   \n",
       "4      0                           0         0            0             0   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0           0                 1              0          0             0   \n",
       "1           0                 1              0          0             0   \n",
       "2           0                 0              0          0             0   \n",
       "3           0                 0              0          1             0   \n",
       "4           0                 1              0          0             0   \n",
       "\n",
       "   Support Devices                                         embeddings  \n",
       "0                1  [0.0029132624622434378, 0.1020001769065857, 0....  \n",
       "1                0  [0.0014348188415169716, 0.0543656125664711, 0....  \n",
       "2                0  [0.001982336398214102, 0.040021587163209915, 0...  \n",
       "3                0  [0.001741771469824016, 0.0560498870909214, 0.1...  \n",
       "4                0  [9.678312198957428e-05, 0.12247737497091293, 0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['gender', 'race', 'age', 'Atelectasis',\n",
    "       'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "       'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding',\n",
    "       'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax',\n",
    "       'Support Devices', 'embeddings']\n",
    "train = train[col]\n",
    "valid = valid[col]\n",
    "test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test removed rows = 51\n",
      "Number of train removed rows = 67\n",
      "Number of valid removed rows = 3\n"
     ]
    }
   ],
   "source": [
    "# Remove images that could not be processed\n",
    "\n",
    "initial_size = test.shape[0] \n",
    "test = test[test['embeddings'].apply(type) == list]\n",
    "final_size = test.shape[0] \n",
    "print(f'Number of test removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = train.shape[0] \n",
    "train = train[train['embeddings'].apply(type) == list]\n",
    "final_size = train.shape[0] \n",
    "print(f'Number of train removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = valid.shape[0]\n",
    "valid = valid[valid['embeddings'].apply(type) == list]\n",
    "final_size = valid.shape[0] \n",
    "print(f'Number of valid removed rows = {initial_size - final_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = pd.DataFrame(train['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test['embeddings'].tolist())\n",
    "valid_embeddings = pd.DataFrame(valid['embeddings'].tolist())\n",
    "\n",
    "# Diseases to predict\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "y_valid = valid[diseases]\n",
    "\n",
    "X_train = train_embeddings\n",
    "X_test = test_embeddings\n",
    "X_valid = valid_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sex = test['gender']\n",
    "y_race = test['race']\n",
    "y_age = test['age']\n",
    "\n",
    "y_sex_valid = valid['gender']\n",
    "y_race_valid = valid['race']\n",
    "y_age_valid = valid['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_742448/1493216315.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train.replace(-1, 0, inplace=True)\n",
      "/tmp/ipykernel_742448/1493216315.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test.replace(-1, 0, inplace=True)\n",
      "/tmp/ipykernel_742448/1493216315.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_valid.replace(-1, 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)\n",
    "y_valid.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA to reduce embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 305\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "X_valid_scaled = scaler.transform(np.stack(valid_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "#95% variance means that the selected principal components (reduced dimensions) retain 95% of the total variability present in the original high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)\n",
    "x_valid_subset = pca.transform(X_valid_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning and train testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    \n",
    "    if y_train.shape[1] > 1:\n",
    "        multi_output_model = MultiOutputClassifier(model)\n",
    "        multi_output_model.fit(x_train, y_train)\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test))}) # Dataframe with probabilites \n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "    else:\n",
    "        print(\"Single disease\")\n",
    "        model.fit(x_train, y_train)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            # Dataframe with probabilities for the positive class\n",
    "            y_test_preds_proba = pd.DataFrame(model.predict_proba(x_test)[:, 1], columns=['Probability'])\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search for hyperparameters\n",
    "# Starting large, then reduce the search space\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.01, 0.05, 0.07, 0.1],\n",
    "    'n_estimators':     [100, 150, 200, 250],\n",
    "    'max_depth':        [5, 10, 15],\n",
    "    'min_child_weight': [5, 10],\n",
    "    'gamma':            [0.1],\n",
    "    'subsample':        [1.0],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'reg_lambda':       [0],\n",
    "    'reg_alpha':        [10],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "n_iter = 50\n",
    "sampler = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "results = []\n",
    "for params in tqdm(sampler, desc=\"Hyperparameter search\"):\n",
    "    # always fix these two\n",
    "    params_fixed = {\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric':        'logloss',\n",
    "        'random_state':       42,\n",
    "        **params\n",
    "    }\n",
    "    model = XGBClassifier(**params_fixed)\n",
    "\n",
    "    # train & get probability predictions\n",
    "    y_pred_proba = train_model(\n",
    "        x_train=x_train_subset,\n",
    "        y_train=y_train,\n",
    "        x_test= x_valid_subset,\n",
    "        y_test= y_valid,\n",
    "        model= model\n",
    "    )\n",
    "\n",
    "    predictions = y_pred_proba.values\n",
    "    targets = y_valid.values\n",
    "\n",
    "    y_pred_df = pd.DataFrame(y_pred_proba)\n",
    "    y_pred_df.columns = diseases\n",
    "    y_valid_df = pd.DataFrame(y_valid)\n",
    "    y_valid_df.columns = diseases\n",
    "\n",
    "    metrics = compute_metrics(y_pred_df, y_valid_df, diseases)\n",
    "\n",
    "    metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old = compute_metrics_subcath(predictions, targets, diseases, y_sex_valid, y_race_valid, y_age_valid)\n",
    "    styled_df, df = bias_table(metrics, metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old)\n",
    "\n",
    "    score = (df['AUPRC'].mean() - (df['Delta AUPRC sex'].mean() + df['Delta AUPRC race'].mean() + df['Delta AUPRC age'].mean()))\n",
    "\n",
    "    results.append({\n",
    "        **params_fixed,\n",
    "        'objective (higher better)': score\n",
    "    })\n",
    "\n",
    "# turn into a DataFrame and sort\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('objective (higher better)', ascending=False)\n",
    "\n",
    "# best row  \n",
    "best = results_df.iloc[0]\n",
    "print(\"Best params:\\n\", best.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:16:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:16:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:17:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:17:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:17:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:17:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:18:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:18:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:18:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:18:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:18:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:19:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:19:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:19:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:19:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:20:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:20:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:20:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:20:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:20:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    x_train_shuffled, y_train_shuffled = shuffle(x_train_subset, y_train, random_state=i)\n",
    "    \n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,         # Disables the deprecated label encoder warning\n",
    "    eval_metric='logloss',           # Evaluation metric for validation data\n",
    "    learning_rate=0.05,              # Step size shrinkage used to prevent overfitting\n",
    "    n_estimators=150,                # Number of gradient boosted trees. Equivalent to the number of boosting rounds\n",
    "    max_depth=10,                    # Maximum depth of a tree\n",
    "    min_child_weight=5,              # Minimum sum of instance weight (hessian) needed in a child\n",
    "    gamma=0.1,                       # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    subsample=1.0,                   # Subsample ratio of the training instances\n",
    "    colsample_bytree=0.8,            # Subsample ratio of columns when constructing each tree\n",
    "    colsample_bylevel=1,             # Subsample ratio of columns for each level\n",
    "    colsample_bynode=1,              # Subsample ratio of columns for each split\n",
    "    reg_lambda=0,                    # L2 regularization term on weights\n",
    "    reg_alpha=10,                    # L1 regularization term on weights\n",
    "    scale_pos_weight=1,              # Balancing of positive and negative weights\n",
    "    random_state=i                  \n",
    ")\n",
    "    \n",
    " \n",
    "    y_pred = train_model(\n",
    "        x_train=x_train_shuffled, \n",
    "        y_train=y_train_shuffled, \n",
    "        x_test=x_test_subset, \n",
    "        y_test=y_test, \n",
    "        model=xgb_model, \n",
    "    )\n",
    "\n",
    "    predictions = y_pred.values\n",
    "    targets = y_test.values\n",
    "\n",
    "    y_pred_df = pd.DataFrame(y_pred)\n",
    "    y_pred_df.columns = diseases\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "    y_test_df.columns = diseases\n",
    "\n",
    "    metrics = compute_metrics(y_pred_df, y_test_df, diseases)\n",
    "    metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old = compute_metrics_subcath(predictions, targets, diseases, y_sex, y_race, y_age)\n",
    "    styled_df, df = bias_table_auprc(metrics, metrics_female, metrics_male, metrics_white, metrics_black, metrics_asian, metrics_young, metrics_old)\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(dataframes, keys=range(len(dataframes)))\n",
    "\n",
    "combined_df = combined_df[['AUPRC', 'AUC', 'Delta AUPRC sex', 'Delta AUPRC race', 'Delta AUPRC age']]\n",
    "\n",
    "df_mean = combined_df.groupby(level=1).mean()\n",
    "df_std = combined_df.groupby(level=1).std() \n",
    "\n",
    "df_mean.reset_index(drop=True, inplace=True)\n",
    "df_std.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_mean.insert(0, 'disease', diseases)\n",
    "df_std.insert(0, 'disease', diseases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e351b_row0_col1, #T_e351b_row0_col5, #T_e351b_row1_col2, #T_e351b_row1_col3, #T_e351b_row1_col4 {\n",
       "  background-color: #fff7ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row0_col2 {\n",
       "  background-color: #960000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e351b_row0_col3, #T_e351b_row0_col4, #T_e351b_row2_col5, #T_e351b_row3_col1, #T_e351b_row3_col2 {\n",
       "  background-color: #7f0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e351b_row1_col1 {\n",
       "  background-color: #cd2316;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e351b_row1_col5 {\n",
       "  background-color: #fff2e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row2_col1 {\n",
       "  background-color: #fdc28b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row2_col2 {\n",
       "  background-color: #d32a1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e351b_row2_col3 {\n",
       "  background-color: #feefda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row2_col4 {\n",
       "  background-color: #fdcb95;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row3_col3 {\n",
       "  background-color: #fee5c1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row3_col4 {\n",
       "  background-color: #fda872;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e351b_row3_col5 {\n",
       "  background-color: #f26d4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e351b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e351b_level0_col0\" class=\"col_heading level0 col0\" >disease</th>\n",
       "      <th id=\"T_e351b_level0_col1\" class=\"col_heading level0 col1\" >AUPRC</th>\n",
       "      <th id=\"T_e351b_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e351b_level0_col3\" class=\"col_heading level0 col3\" >Delta AUPRC sex</th>\n",
       "      <th id=\"T_e351b_level0_col4\" class=\"col_heading level0 col4\" >Delta AUPRC race</th>\n",
       "      <th id=\"T_e351b_level0_col5\" class=\"col_heading level0 col5\" >Delta AUPRC age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e351b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e351b_row0_col0\" class=\"data row0 col0\" >Cardiomegaly</td>\n",
       "      <td id=\"T_e351b_row0_col1\" class=\"data row0 col1\" >39.6</td>\n",
       "      <td id=\"T_e351b_row0_col2\" class=\"data row0 col2\" >80.7</td>\n",
       "      <td id=\"T_e351b_row0_col3\" class=\"data row0 col3\" >4.3</td>\n",
       "      <td id=\"T_e351b_row0_col4\" class=\"data row0 col4\" >17.2</td>\n",
       "      <td id=\"T_e351b_row0_col5\" class=\"data row0 col5\" >0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e351b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e351b_row1_col0\" class=\"data row1 col0\" >Lung Opacity</td>\n",
       "      <td id=\"T_e351b_row1_col1\" class=\"data row1 col1\" >64.3</td>\n",
       "      <td id=\"T_e351b_row1_col2\" class=\"data row1 col2\" >69.3</td>\n",
       "      <td id=\"T_e351b_row1_col3\" class=\"data row1 col3\" >0.4</td>\n",
       "      <td id=\"T_e351b_row1_col4\" class=\"data row1 col4\" >1.3</td>\n",
       "      <td id=\"T_e351b_row1_col5\" class=\"data row1 col5\" >0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e351b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e351b_row2_col0\" class=\"data row2 col0\" >Edema</td>\n",
       "      <td id=\"T_e351b_row2_col1\" class=\"data row2 col1\" >50.5</td>\n",
       "      <td id=\"T_e351b_row2_col2\" class=\"data row2 col2\" >78.5</td>\n",
       "      <td id=\"T_e351b_row2_col3\" class=\"data row2 col3\" >0.6</td>\n",
       "      <td id=\"T_e351b_row2_col4\" class=\"data row2 col4\" >6.0</td>\n",
       "      <td id=\"T_e351b_row2_col5\" class=\"data row2 col5\" >5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e351b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e351b_row3_col0\" class=\"data row3 col0\" >Pleural Effusion</td>\n",
       "      <td id=\"T_e351b_row3_col1\" class=\"data row3 col1\" >71.2</td>\n",
       "      <td id=\"T_e351b_row3_col2\" class=\"data row3 col2\" >81.4</td>\n",
       "      <td id=\"T_e351b_row3_col3\" class=\"data row3 col3\" >1.0</td>\n",
       "      <td id=\"T_e351b_row3_col4\" class=\"data row3 col4\" >8.1</td>\n",
       "      <td id=\"T_e351b_row3_col5\" class=\"data row3 col5\" >3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd9658280a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Styling the DataFrame\n",
    "styled_df = df_mean.style.format({\n",
    "    'AUPRC': \"{:.1f}\",\n",
    "    'AUC': \"{:.1f}\",\n",
    "    'Delta AUPRC sex': \"{:.1f}\",\n",
    "    'Delta AUPRC race': \"{:.1f}\",\n",
    "    'Delta AUPRC age': \"{:.1f}\",\n",
    "}).background_gradient(cmap='OrRd', subset=[\n",
    "    'AUPRC', 'AUC', 'Delta AUPRC sex', 'Delta AUPRC race', 'Delta AUPRC age'\n",
    "])\n",
    "styled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
