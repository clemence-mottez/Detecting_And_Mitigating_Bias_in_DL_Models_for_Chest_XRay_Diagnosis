{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from scipy.stats import entropy\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/cmottez/CS231N_Lightweight_Bias_Mitigation_Chest_Xray')\n",
    "\n",
    "from metrics import compute_metrics, compute_kl_divergence_sex, compute_kl_divergence_age, compute_kl_divergence_race, compute_metrics_subcath, bias_table, bias_table_auprc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_train_with_embeddings_extracted.pkl')\n",
    "valid = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_valid_with_embeddings_extracted.pkl')\n",
    "test = pd.read_pickle('../data/embeddings_chexpert/CNNs/chexpert_on_chexpert_test_with_embeddings_extracted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>insurance</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0029132624622434378, 0.1020001769065857, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0014348188415169716, 0.0543656125664711, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001982336398214102, 0.040021587163209915, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001741771469824016, 0.0560498870909214, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.678312198957428e-05, 0.12247737497091293, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  race  age  insurance  Atelectasis  Cardiomegaly  Consolidation  \\\n",
       "0       1     0    1          1            1             1              0   \n",
       "1       0     1    0          2            0             0              0   \n",
       "2       0     0    1          1            0             0              0   \n",
       "3       1     1    1          1            0             0              0   \n",
       "4       0     0    0          0            0             0              1   \n",
       "\n",
       "   Edema  Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0      1                           0         1            0             0   \n",
       "1      0                           0         0            0             0   \n",
       "2      0                           0         0            0             1   \n",
       "3      0                           0         0            0             0   \n",
       "4      0                           0         0            0             0   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0           0                 1              0          0             0   \n",
       "1           0                 1              0          0             0   \n",
       "2           0                 0              0          0             0   \n",
       "3           0                 0              0          1             0   \n",
       "4           0                 1              0          0             0   \n",
       "\n",
       "   Support Devices                                         embeddings  \n",
       "0                1  [0.0029132624622434378, 0.1020001769065857, 0....  \n",
       "1                0  [0.0014348188415169716, 0.0543656125664711, 0....  \n",
       "2                0  [0.001982336398214102, 0.040021587163209915, 0...  \n",
       "3                0  [0.001741771469824016, 0.0560498870909214, 0.1...  \n",
       "4                0  [9.678312198957428e-05, 0.12247737497091293, 0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['gender', 'race', 'age', 'Atelectasis',\n",
    "       'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "       'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding',\n",
    "       'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax',\n",
    "       'Support Devices', 'embeddings']\n",
    "train = train[col]\n",
    "valid = valid[col]\n",
    "test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test removed rows = 51\n",
      "Number of train removed rows = 67\n"
     ]
    }
   ],
   "source": [
    "initial_size = test.shape[0] \n",
    "test = test[test['embeddings'].apply(type) == list]\n",
    "final_size = test.shape[0] \n",
    "print(f'Number of test removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = train.shape[0] \n",
    "train = train[train['embeddings'].apply(type) == list]\n",
    "final_size = train.shape[0] \n",
    "print(f'Number of train removed rows = {initial_size - final_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = pd.DataFrame(train['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test['embeddings'].tolist())\n",
    "\n",
    "# Diseases to predict\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "            'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "# diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']\n",
    "diseases = ['Pleural Effusion']\n",
    "# diseases = ['gender']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "\n",
    "X_train = train_embeddings\n",
    "X_test = test_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sex = test['gender']\n",
    "y_race = test['race']\n",
    "y_age = test['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3074475/3958011541.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train.replace(-1, 0, inplace=True)\n",
      "/tmp/ipykernel_3074475/3958011541.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test.replace(-1, 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (0.44.1)\n",
      "Requirement already satisfied: numpy in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in /home/cmottez/.local/lib/python3.8/site-packages (from shap) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.7 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (0.58.1)\n",
      "Requirement already satisfied: cloudpickle in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from numba->shap) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from numba->shap) (8.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages (from importlib-metadata->numba->shap) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP array shape: (40307, 1024) vs X_test shape: (40307, 1024)\n",
      "Top gender‐differentiated features:\n",
      "1      0.0\n",
      "13     0.0\n",
      "23     0.0\n",
      "43     0.0\n",
      "56     0.0\n",
      "60     0.0\n",
      "78     0.0\n",
      "90     0.0\n",
      "99     0.0\n",
      "105    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Each of the input arrays is constant;the F statistic is not defined or infinite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top race‐differentiated features:\n",
      "238     0.000000e+00\n",
      "293     0.000000e+00\n",
      "304     0.000000e+00\n",
      "435     0.000000e+00\n",
      "312    1.482197e-323\n",
      "475    6.200524e-321\n",
      "172    8.692097e-320\n",
      "10     1.427864e-313\n",
      "316    2.530774e-292\n",
      "170    3.434928e-291\n",
      "dtype: float64\n",
      "Top age‐differentiated features:\n",
      "63     0.0\n",
      "66     0.0\n",
      "83     0.0\n",
      "98     0.0\n",
      "117    0.0\n",
      "120    0.0\n",
      "160    0.0\n",
      "165    0.0\n",
      "182    0.0\n",
      "202    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from scipy.stats import ttest_ind, f_oneway, spearmanr\n",
    "\n",
    "# ——— 1. Train on full data ———\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    solver='liblinear', \n",
    "    random_state=0\n",
    ")\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# ——— 2. Compute SHAP with the new API ———\n",
    "explainer = shap.Explainer(clf, X_train)\n",
    "shap_exp  = explainer(X_test)\n",
    "\n",
    "# shap_exp.values is now (n_samples, n_features)\n",
    "shap_vals = shap_exp.values\n",
    "print(\"SHAP array shape:\", shap_vals.shape, \"vs X_test shape:\", X_test.shape)\n",
    "\n",
    "# ——— 3. Build DataFrame of SHAP + subgroup labels ———\n",
    "assert shap_vals.shape[1] == X_test.shape[1], \"Mismatch in #features!\"\n",
    "shap_df = pd.DataFrame(shap_vals, columns=X_test.columns)\n",
    "shap_df['gender'] = y_sex.values\n",
    "shap_df['race']   = y_race.values\n",
    "shap_df['age']    = y_age.values\n",
    "\n",
    "# ——— 4. Statistical comparisons ———\n",
    "\n",
    "# 4a) Gender (binary t‐test)\n",
    "g0, g1 = shap_df['gender'].unique()[:2]\n",
    "p_gender = {\n",
    "    feat: ttest_ind(\n",
    "             shap_df.loc[shap_df['gender']==g0, feat],\n",
    "             shap_df.loc[shap_df['gender']==g1, feat],\n",
    "             equal_var=False\n",
    "           ).pvalue\n",
    "    for feat in X_test.columns\n",
    "}\n",
    "print(\"Top gender‐differentiated features:\")\n",
    "print(pd.Series(p_gender).nsmallest(10))\n",
    "\n",
    "# 4b) Race (one‐way ANOVA)\n",
    "races = shap_df['race'].unique()\n",
    "p_race = {}\n",
    "for feat in X_test.columns:\n",
    "    groups = [shap_df.loc[shap_df['race']==r, feat] for r in races]\n",
    "    p_race[feat] = f_oneway(*groups).pvalue\n",
    "print(\"\\nTop race‐differentiated features:\")\n",
    "print(pd.Series(p_race).nsmallest(10))\n",
    "\n",
    "# 4a) Age (binary t‐test)\n",
    "g0, g1 = shap_df['age'].unique()[:2]\n",
    "p_gender = {\n",
    "    feat: ttest_ind(\n",
    "             shap_df.loc[shap_df['age']==g0, feat],\n",
    "             shap_df.loc[shap_df['age']==g1, feat],\n",
    "             equal_var=False\n",
    "           ).pvalue\n",
    "    for feat in X_test.columns\n",
    "}\n",
    "print(\"Top age‐differentiated features:\")\n",
    "print(pd.Series(p_gender).nsmallest(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def direction_by_group(shap_df, subgroup_col, features):\n",
    "    \"\"\"\n",
    "    Returns for each feature whether its mean SHAP sign is the same\n",
    "    across all levels of subgroup_col, or flips in at least one.\n",
    "    \n",
    "    shap_df: DataFrame, columns = features + subgroup_col\n",
    "    subgroup_col: e.g. 'gender' or 'race'\n",
    "    features: list of feature names to check\n",
    "    \"\"\"\n",
    "    # 1) Compute mean SHAP (signed) per group\n",
    "    mean_shap = shap_df.groupby(subgroup_col)[features].mean()\n",
    "    # 2) Extract the sign of each mean: +1, 0, or -1\n",
    "    sign_df = mean_shap.apply(np.sign)\n",
    "    \n",
    "    result = {}\n",
    "    for feat in features:\n",
    "        signs = sign_df[feat].unique()\n",
    "        # remove any zeros (exactly zero is rare, but treat as neutral)\n",
    "        signs = set(s for s in signs if s != 0)\n",
    "        if len(signs) <= 1:\n",
    "            result[feat] = 'same direction'\n",
    "        else:\n",
    "            result[feat] = 'opposite direction'\n",
    "    return pd.Series(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 for 0: [773, 950, 781, 696, 603]\n",
      "Top 5 for 1: [950, 696, 603, 773, 781]\n",
      "\n",
      "Common features (5): [603, 696, 773, 781, 950]\n",
      "0-only (0): []\n",
      "1-only (0): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ——— assume you already have shap_df with feature columns + 'gender' ———\n",
    "features = X_test.columns\n",
    "\n",
    "# 1) Compute mean(|SHAP|) per feature per gender\n",
    "mean_abs = (\n",
    "    shap_df\n",
    "    .groupby('gender')[features]\n",
    "    .apply(lambda df: df.abs().mean())\n",
    ")\n",
    "# `mean_abs` is now a DataFrame indexed by gender, columns = features\n",
    "\n",
    "# 2) Sort and grab top‑N for each gender\n",
    "top_n = 5\n",
    "g0, g1 = mean_abs.index[:2]   # e.g. 'M' and 'F'\n",
    "male_ranked   = mean_abs.loc[g0].sort_values(ascending=False)\n",
    "female_ranked = mean_abs.loc[g1].sort_values(ascending=False)\n",
    "\n",
    "male_top    = male_ranked.iloc[:top_n].index.tolist()\n",
    "female_top  = female_ranked.iloc[:top_n].index.tolist()\n",
    "\n",
    "print(f\"Top {top_n} for {g0}:\", male_top)\n",
    "print(f\"Top {top_n} for {g1}:\", female_top)\n",
    "\n",
    "# 3) Compute overlap and differences\n",
    "set_m = set(male_top)\n",
    "set_f = set(female_top)\n",
    "\n",
    "common      = set_m & set_f\n",
    "male_only   = set_m - set_f\n",
    "female_only = set_f - set_m\n",
    "\n",
    "print(f\"\\nCommon features ({len(common)}):\", sorted(common))\n",
    "print(f\"{g0}-only ({len(male_only)}):\", sorted(male_only))\n",
    "print(f\"{g1}-only ({len(female_only)}):\", sorted(female_only))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction comparison:\n",
      "773        same direction\n",
      "781    opposite direction\n",
      "950    opposite direction\n",
      "696        same direction\n",
      "603        same direction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "top_union_gender = list(set(male_top) | set(female_top))\n",
    "\n",
    "direction_gender = direction_by_group(shap_df, 'gender', top_union_gender)\n",
    "print(\"Gender direction comparison:\")\n",
    "print(direction_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 for 0: [950, 696, 773, 603, 781]\n",
      "Top 5 for 1: [773, 950, 603, 781, 696]\n",
      "\n",
      "Common features (5): [603, 696, 773, 781, 950]\n",
      "0-only (0): []\n",
      "1-only (0): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ——— assume you already have shap_df with feature columns + 'gender' ———\n",
    "features = X_test.columns\n",
    "\n",
    "# 1) Compute mean(|SHAP|) per feature per gender\n",
    "mean_abs = (\n",
    "    shap_df\n",
    "    .groupby('age')[features]\n",
    "    .apply(lambda df: df.abs().mean())\n",
    ")\n",
    "# `mean_abs` is now a DataFrame indexed by gender, columns = features\n",
    "\n",
    "# 2) Sort and grab top‑N for each gender\n",
    "top_n = 5\n",
    "g0, g1 = mean_abs.index[:2]   # e.g. 'M' and 'F'\n",
    "young_ranked   = mean_abs.loc[g0].sort_values(ascending=False)\n",
    "old_ranked = mean_abs.loc[g1].sort_values(ascending=False)\n",
    "\n",
    "young_top    = young_ranked.iloc[:top_n].index.tolist()\n",
    "old_top  = old_ranked.iloc[:top_n].index.tolist()\n",
    "\n",
    "print(f\"Top {top_n} for {g0}:\", young_top)\n",
    "print(f\"Top {top_n} for {g1}:\", old_top)\n",
    "\n",
    "# 3) Compute overlap and differences\n",
    "set_y = set(young_top)\n",
    "set_o = set(old_top)\n",
    "\n",
    "common      = set_y & set_o\n",
    "young_only   = set_y - set_o\n",
    "old_only = set_o - set_y\n",
    "\n",
    "print(f\"\\nCommon features ({len(common)}):\", sorted(common))\n",
    "print(f\"{g0}-only ({len(young_only)}):\", sorted(young_only))\n",
    "print(f\"{g1}-only ({len(old_only)}):\", sorted(old_only))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age direction comparison:\n",
      "773        same direction\n",
      "781        same direction\n",
      "950    opposite direction\n",
      "696    opposite direction\n",
      "603    opposite direction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "top_union_age = list(set(young_top) | set(old_top))\n",
    "\n",
    "direction_age = direction_by_group(shap_df, 'age', top_union_age)\n",
    "print(\"Age direction comparison:\")\n",
    "print(direction_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 per race:\n",
      " Race 0: [773, 950, 696, 603, 781]\n",
      " Race 1: [950, 696, 603, 773, 781]\n",
      " Race 2: [950, 696, 773, 603, 781]\n",
      "\n",
      "Common to all three races: [603, 696, 773, 781, 950]\n",
      "\n",
      "Common to exactly two races:\n",
      " Races (0, 1): []\n",
      " Races (0, 2): []\n",
      " Races (1, 2): []\n",
      "\n",
      "Unique per race:\n",
      " Race 0-only: []\n",
      " Race 1-only: []\n",
      " Race 2-only: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# ——— assume shap_df has your SHAP values + a 'race' column ———\n",
    "features = X_test.columns\n",
    "top_n   = 5\n",
    "\n",
    "# 1) Mean absolute SHAP per feature per race\n",
    "mean_abs_race = (\n",
    "    shap_df\n",
    "    .groupby('race')[features]\n",
    "    .apply(lambda df: df.abs().mean())\n",
    ")\n",
    "# mean_abs_race: index=race values, columns=features\n",
    "\n",
    "# 2) Get top-N for each race\n",
    "race_top = {}\n",
    "for race in mean_abs_race.index:\n",
    "    ranked = mean_abs_race.loc[race].sort_values(ascending=False)\n",
    "    race_top[race] = ranked.iloc[:top_n].index.tolist()\n",
    "\n",
    "# 3) Compare across races\n",
    "sets = {r: set(flist) for r, flist in race_top.items()}\n",
    "\n",
    "# 3a) Features common to ALL three races\n",
    "common_all = set.intersection(*sets.values())\n",
    "\n",
    "# 3b) Features common to exactly two races\n",
    "common_pairs = {}\n",
    "for (r1, r2) in itertools.combinations(sets.keys(), 2):\n",
    "    common_pairs[(r1, r2)] = sets[r1] & sets[r2] - common_all\n",
    "\n",
    "# 3c) Features unique to each race\n",
    "unique_per_race = {\n",
    "    r: sets[r] - set.union(*(sets[r2] for r2 in sets if r2 != r))\n",
    "    for r in sets\n",
    "}\n",
    "\n",
    "# 4) Print results\n",
    "print(f\"Top {top_n} per race:\")\n",
    "for r, flist in race_top.items():\n",
    "    print(f\" Race {r}: {flist}\")\n",
    "\n",
    "print(\"\\nCommon to all three races:\", sorted(common_all))\n",
    "print(\"\\nCommon to exactly two races:\")\n",
    "for pair, feats in common_pairs.items():\n",
    "    print(f\" Races {pair}: {sorted(feats)}\")\n",
    "\n",
    "print(\"\\nUnique per race:\")\n",
    "for r, feats in unique_per_race.items():\n",
    "    print(f\" Race {r}-only: {sorted(feats)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Race direction comparison:\n",
      "773        same direction\n",
      "781        same direction\n",
      "950    opposite direction\n",
      "696    opposite direction\n",
      "603        same direction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "top_union_race = list(set(race_top[0]) | set(race_top[1]) | set(race_top[2]))\n",
    "\n",
    "direction_race = direction_by_group(shap_df, 'race', top_union_race)\n",
    "print(\"\\nRace direction comparison:\")\n",
    "print(direction_race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
